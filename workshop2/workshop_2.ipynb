{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oT5ZdGyV0Jqx"
   },
   "source": [
    "# Sequence-to-Sequence Neural Networks\n",
    "\n",
    "We want to build a model that translate a German sentence to its English version.\n",
    "\n",
    "(Based on [this](https://github.com/bentrevett/pytorch-seq2seq) very nice tutorial series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySJjNMpBaW9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already satisfied: de_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.1.0/de_core_news_sm-2.1.0.tar.gz#egg=de_core_news_sm==2.1.0 in /Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages/de_core_news_sm -->\n",
      "/Users/YuHsiangLo/anaconda3/lib/python3.7/site-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "! python -m spacy download en\n",
    "! python -m spacy download de\n",
    "\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dwXhZoxOaW98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H73EcKY0aW-R"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "#### Define `Field`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fmyJ4SDwaW-V"
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    '''\n",
    "    Tokenizes German text from a string into a list of strings (tokens)\n",
    "    '''\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    '''\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    '''\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SRC = Field(tokenize=tokenize_de, \n",
    "            init_token='<sos>', \n",
    "            eos_token='<eos>', \n",
    "            lower=True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize_en, \n",
    "            init_token='<sos>', \n",
    "            eos_token='<eos>', \n",
    "            lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False, False, True, False, True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD = '<PAD>'\n",
    "UNK = '<UNK>'\n",
    "START = '<SOS>'\n",
    "END = '<EOS>'\n",
    "\n",
    "def capital(string):\n",
    "    return [True if word[0].isupper() else False for word in string.split()]\n",
    "\n",
    "WORD = Field(sequential=True, pad_token = PAD, unk_token = UNK, init_token = START, eos_token = END)\n",
    "CHAR = Field(sequential=True, tokenize = capital, pad_token = PAD, unk_token = UNK, init_token = START, eos_token = END)\n",
    "\n",
    "CHAR.preprocess('I do not know What this Is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xJUACxNxaW-m"
   },
   "source": [
    "#### Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xA5V4kqaW-q"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(exts=('.de', '.en'), \n",
    "                                                    fields=(CHAR, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YW9jIOjTaW_B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n"
     ]
    }
   ],
   "source": [
    "# of examples in each set\n",
    "print(f'Number of training examples: {len(train_data.examples)}')\n",
    "print(f'Number of validation examples: {len(valid_data.examples)}')\n",
    "print(f'Number of testing examples: {len(test_data.examples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0lRxKbRaW_O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': [True,\n",
      "         False,\n",
      "         False,\n",
      "         True,\n",
      "         False,\n",
      "         False,\n",
      "         True,\n",
      "         False,\n",
      "         False,\n",
      "         True,\n",
      "         False,\n",
      "         True],\n",
      " 'trg': ['two',\n",
      "         'young',\n",
      "         ',',\n",
      "         'white',\n",
      "         'males',\n",
      "         'are',\n",
      "         'outside',\n",
      "         'near',\n",
      "         'many',\n",
      "         'bushes',\n",
      "         '.']}\n"
     ]
    }
   ],
   "source": [
    "# Let's see one example\n",
    "pprint(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "38k5IOtlaW_Z"
   },
   "source": [
    "#### Build vocab\n",
    "- `min_freq` = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgsthdHTaW_g"
   },
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukpvmXAwaW_u"
   },
   "outputs": [],
   "source": [
    "print(SRC.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdJyMZ-PaW_4"
   },
   "outputs": [],
   "source": [
    "print(f'Unique tokens in source (de) vocabulary: {len(SRC.vocab)}')\n",
    "print(f'Unique tokens in target (en) vocabulary: {len(TRG.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMZnJ_wcaXAI"
   },
   "source": [
    "#### Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEtbhp4_aXAO"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Z8kfwhtaXAe"
   },
   "outputs": [],
   "source": [
    "ex = next(iter(train_iterator))\n",
    "print(ex)\n",
    "print(ex.src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vpyuUzeaXAw"
   },
   "source": [
    "## Foundations\n",
    "\n",
    "- sequence-to-sequence (seq2seq) models\n",
    "  - Example:\n",
    "    - Input: `<sos> guten morgen <eos>`\n",
    "    - Output: `<sos> good morning <eos>`\n",
    "  - **encoder-decoder** models: RNN to encode + RNN to decode\n",
    "  - **context vector**: an abstract representation of the entire input sentence.\n",
    "\n",
    "### Vanilla RNN\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq1.png?raw=1)\n",
    "\n",
    "- More formally...\n",
    "    - Input: $X = [x_1, x_2, ..., x_T]$\n",
    "    - Target: $Y = [y_1, y_2, ..., y_{T'}]$\n",
    "    - Prediction: $\\hat{Y} = [\\hat{y}_1, \\hat{y}_2, ..., \\hat{y}_T]$\n",
    "    - **Encoder**\n",
    "    $$h_t = \\text{EncoderRNN}(e(x_t), h_{t-1})$$\n",
    "      - $e(x_t)$: embedding (word $x_t$ $\\rightarrow$ vector)\n",
    "      - $h_t$: hidden state at $t$\n",
    "      - $z = h_T$: context vector\n",
    "  \n",
    "    - **Decoder**\n",
    "    $$s_t = \\text{DecoderRNN}(e'(y_t), s_{t-1})$$\n",
    "      - $e'(y_t)$: embedding (word $y_t$ $\\rightarrow$ vector)\n",
    "      - $s_t$: hidden state at $t$\n",
    "\n",
    "    - **Linear layer**\n",
    "    $$\\hat{y}_t = f(s_t)$$\n",
    "      - $f$: a full-connected NN\n",
    "    \n",
    "### LSTM (now we have cells!)\n",
    "\n",
    "(If you want to learn more about LSTM, read [this](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)!)\n",
    "\n",
    "- **Encoder**: $(h_t, c_t) = \\text{EncoderLSTM}(e(x_t), (h_{t-1}, c_{t-1}))$\n",
    "    \n",
    "- **Decoder**: $(s_t, c_t) = \\text{DecoderLSTM}(e'(y_t), (s_{t-1}, c_{t-1}))$\n",
    "\n",
    "- **Linear layer**: $\\hat{y}_{t} = f(s_t)$\n",
    "\n",
    "- Can have more than one layer\n",
    "\n",
    "![](https://github.com/bentrevett/pytorch-seq2seq/blob/master/assets/seq2seq4.png?raw=1)\n",
    "\n",
    "- Encoder:\n",
    "    \n",
    "$$\\begin{align*}\n",
    "(h_t^1, c_t^1) &= \\text{EncoderLSTM}^1(e(x_t), (h_{t-1}^1, c_{t-1}^1))\\\\\n",
    "(h_t^2, c_t^2) &= \\text{EncoderLSTM}^2(h_t^1, (h_{t-1}^2, c_{t-1}^2))\n",
    "\\end{align*}$$\n",
    "\n",
    "- Decoder:\n",
    "\n",
    "$$\\begin{align*}\n",
    "(s_t^1, c_t^1) = \\text{DecoderLSTM}^1(e'(y_t), (s_{t-1}^1, c_{t-1}^1))\\\\\n",
    "(s_t^2, c_t^2) = \\text{DecoderLSTM}^2(s_t^1, (s_{t-1}^2, c_{t-1}^2))\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apyY4b9OaXA0"
   },
   "source": [
    "## Create Encoder in `PyTorch`\n",
    "\n",
    "(Let's draw something!)\n",
    "\n",
    "- `torch.nn.Embedding`\n",
    "  - Constructor arguments:\n",
    "    - `num_embeddings`: the size of the dictionary (vocab) of embeddings.\n",
    "    - `embedding_dim`: the size of each embedding vector.\n",
    "  - Input $\\rightarrow$ output:\n",
    "    - (src_len, batch_size) $\\rightarrow$ (src_len, batch_size, embedding_dim)\n",
    "\n",
    "- `torch.nn.LSTM`\n",
    "  - Constructor arguments:\n",
    "    - `input_size`: the dimensionality of the embedding layer.\n",
    "    - `hidden_size`: the dimensionality of the **hidden** and **cell** states.\n",
    "    - `num_layers`: the number of layers in the RNN.\n",
    "    - `dropout`: the amount of dropout to use. This is a regularization parameter to prevent overfitting.\n",
    "    - `bidirectional`(**False**)\n",
    "  - Input $\\rightarrow$ output, (hidden, cell):\n",
    "    - Default $h_0$ and $c_0$: zero vectors\n",
    "    - (src_len, batch_size, embedding_dim) $\\rightarrow$ (src_len, batch_size, hidden_size \\* n_directions), (num_layers \\* n_directions, batch_size, hidden_size), (n_layers \\* n_directions, batch_size, hidden_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sjRM3qV4aXA2"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_vocab_size, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = (src_len, batch_size)\n",
    "        \n",
    "        embedded = self.embedding(src)\n",
    "        \n",
    "        #embedded = (src_len, batch_size, emb_dim)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs = (src_len, batch_size, hid_dim * n_directions)\n",
    "        #hidden = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        #cell = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4-qvzdsaXBF"
   },
   "source": [
    "## Create Decoder\n",
    "\n",
    "- `torch.nn.Linear`\n",
    "    - Constructor arguments:\n",
    "        - `in_feature`\n",
    "        - `out_feature`\n",
    "    - Input $\\rightarrow$ output:\n",
    "        - (batch_size, hidden_size) $\\rightarrow$ (batch_size, output_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOxbeiIKaXBJ"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.output_vocab_size = output_vocab_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_vocab_size, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_vocab_size)\n",
    "                \n",
    "    def forward(self, input, hidden, cell):\n",
    "        \n",
    "        #input = (batch size)\n",
    "        #hidden = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        #cell = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        #n directions in the decoder will both always be 1, therefore:\n",
    "        #hidden = (n_layers, batch_size, hid_dim)\n",
    "        #context = (n_layers, batch_size, hid_dim)\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = (1, batch_size)\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        \n",
    "        #embedded = (1, batch_size, emb_dim)\n",
    "                \n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        \n",
    "        #output = (seq_len, batch_size, hid_dim * n_directions)\n",
    "        #hidden = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        #cell = (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
    "        #output = (1, batch_size, hid_dim)\n",
    "        #hidden = (n_layers, batch_size, hid_dim)\n",
    "        #cell = (n_layers, batch_size, hid_dim)\n",
    "        \n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        \n",
    "        #prediction = (batch_size, output_dim)\n",
    "        \n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76mv9x1raXBY"
   },
   "source": [
    "## Create Seq2Seq\n",
    "\n",
    "**Note**: our decoder loop starts at 1, not 0. This means the 0th element of our `outputs` tensor remains all zeros. So our `trg` and `outputs` look something like:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} = [\\texttt{<sos>}, &y_1, y_2, y_3, \\texttt{<eos>}]\\\\\n",
    "\\text{outputs} = [0, &\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, \\texttt{<eos>}]\n",
    "\\end{align*}$$\n",
    "\n",
    "Later on when we calculate the loss, we cut off the first element of each tensor to get:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} = [&y_1, y_2, y_3, \\texttt{<eos>}]\\\\\n",
    "\\text{outputs} = [&\\hat{y}_1, \\hat{y}_2, \\hat{y}_3, \\texttt{<eos>}]\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYoVR4XaaXBb"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            'Hidden dimensions of encoder and decoder must be equal!'\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            'Encoder and decoder must have equal number of layers!'\n",
    "        \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        #src = (src len, batch size)\n",
    "        #trg = (trg len, batch size)\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_vocab_size\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #use predicted token as next input\n",
    "            input = top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SaQRoqCsaXBo"
   },
   "source": [
    "Let's see if our model works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyBnSMqaaXBt"
   },
   "outputs": [],
   "source": [
    "INPUT_VOCAB_SIZE = len(SRC.vocab)\n",
    "OUTPUT_VOCAB_SIZE = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_VOCAB_SIZE, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_VOCAB_SIZE, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ms1lATzaXCK"
   },
   "outputs": [],
   "source": [
    "out = model(ex.src, ex.trg)\n",
    "print(out.size())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop_2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
